# LinkedIn Post Ideas - 2025

## Proposed Blog Posts

| Proposed blog post (working title) | Source material & URLs | Notes |
|-----------------------------------|------------------------|-------|
| **The CRAFT Framework: Context Engineering for the LLM Era** | - [2025-08-15: CRAFT Context Engineering framework - Transcend](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7362086675914579970)<br>- [2025-08-13: CRAFT - Fit](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7361353128119529473)<br>- [2025-07-29: CRAFT - Adapt](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7355928475037253633)<br>- [2025-07-19: CRAFT - Resist](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7352293432544927745)<br>- [2025-07-15: CRAFT - Chunk](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7350851966333329410) | These posts form a cohesive series introducing CRAFT (Chunk, Resist, Adapt, Fit, Transcend) as a framework for context engineering with LLMs. Each letter addresses a specific principle: building composable knowledge units, avoiding contradictions, adjusting detail levels, ensuring relevance, and creating platform-independent knowledge. The progression shows a complete methodology for managing context in GenAI systems. |
| **Beyond Vibe-Coding: What Developers Actually Do** | - [2025-08-19: Software development industry profound change](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7363543690583105536)<br>- [2025-03-22: Vibe-coding mental model drift](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7309146789880713216)<br>- [2025-05-04: Vibe-coding relegating corners](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7324809322721435649)<br>- [2025-04-15: Tests are executable spec](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7317694458135793664) | These shares challenge the notion of "vibe-coding" and question what happens when developers' understanding of their codebase drifts from reality. Stacey argues that developers do far more than type code—they make design decisions, manage tacit knowledge, and maintain mental models. The threat isn't GenAI replacing coding, but organizations failing to understand what developers actually contribute beyond syntax. |
| **The Copilot Pause: When AI Interrupts Developer Flow** | - [2025-02-02: Co-pilot pause damaging ergonomic impact](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7291811583922503680)<br>- [2025-11-08: GenAI plan execution and learning](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392902690441285632) | The "co-pilot pause" represents moments when developers stop thinking to await external suggestions, interrupting flow and potentially derailing original thought. Instead of measuring lines of code, what if we measured these uncertainty pauses? The posts explore how GenAI can both help and hinder developer productivity, depending on how it's integrated into workflow. |
| **Essential vs. Accidental Complexity: Where Your Money Goes** | - [2025-11-07: Essential vs accidental complication](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392521881846906880)<br>- [2025-11-07: Software team roles changing](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392358378699792384)<br>- [2025-10-10: Pattern replication and CRUD](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7382356132478095360) | Essential complexity comes from the real-world business domain; accidental complexity comes from over-engineering and organizational dysfunction. At scale, complexity is where money bleeds—through thin-sliced roles, overcomplicated processes, poor developer experience. GenAI has two edges: it replicates overcomplicated patterns from training data, but can also slice through complexity like a machete. Simple is hard and requires thought; use GenAI to delegate what keeps you from thinking deeply. |
| **Testing the Non-Deterministic: Quality in the GenAI Era** | - [2024-12-15: Non-deterministic results are hard](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7274039209177317376)<br>- [2025-02-22: Quality in a GenAI world](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7299063072713822208)<br>- [2025-02-20: Tests never contain conditionals](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7298316100268666881)<br>- [2025-05-31: GenAI can claim 67% pass rate acceptable](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7334382412480630784) | Building software with LLMs produces non-deterministic results, fundamentally changing how we think about testing and quality. Traditional automated checking breaks when output varies run-to-run. The shares explore characterization testing, seed control, parallel validation, and treating tests as specifications that GenAI should not modify. A humorous example: Claude claiming 67% test pass rate is acceptable because "remaining failures are complex timer-based edge cases." |
| **Knowledge Management as Code: From Zettelkasten to Context Engineering** | - [2025-07-03: Context Engineering patterns](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7346489429127032832)<br>- [2025-01-04: Knowledge graphs and multilayer hallucination](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7281319125887381504)<br>- [2025-01-04: Zettelkasten and hierarchical knowledge management](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7281315524020432899)<br>- [2025-01-25: LLMs trained on semantic models](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7288917830987599872) | The intersection of personal knowledge management (Zettelkasten/Atomic Notes), structured LLM responses, prompt engineering, and hierarchical knowledge systems. Stacey explores how knowledge management resembles compilation—moving from AOT (ahead-of-time prompts) to JIT (just-in-time context assembly). LLMs understand formal semantic models like DITA, RDF, OWL, which can provide clearer communication than plain English. |
| **The Ensemble Coding Hypothesis: Real-Time Intent Negotiation** | - [2025-10-12: Alignment is the real bottleneck](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7383116191772409857)<br>- [2025-10-13: Visualizing higher-order concerns from code](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7383490712064925696)<br>- [2025-10-12: Prototyping Actor/Goal/Task system](https://www.linkedin.com/feed/update/urn%3Ali%3AugcPost%3A7383285787649388544)<br>- [2025-10-22: ScreenPlay Pattern and Story Mapping](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7386909269096407040) | The bottleneck isn't coding speed—it's alignment. Meetings that could be clearer, rework from lost intent, waiting for clarification. Stacey experiments with cross-functional ensemble coding sessions (designer, PM, architect, developer) building together in real-time with an LLM as synthesis engine. Not mob programming where one person types—real-time intent negotiation where everyone corrects immediately. Coordination failures drop when everyone sees their intent materialize into code immediately. This extends to visualizing higher-order concerns (architecture, design, interaction) directly from code. |
| **Simple is Hard: Why Developers Need to Own Complexity** | - [2025-11-07: Developers and ROI data](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392552123386789888)<br>- [2025-05-26: SRP and discourse between Martin and Ousterhout](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7332723052461395969)<br>- [2025-02-18: Don't Repeat Yourself evolution](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7297610953204912128) | Developers get labeled as "typing code" but effective teams know how everything they do impacts the business. They're not short-order cooks—they apply their skills to business problems. Simple design is harder than complex; it requires thought. The progression from novice to expert understanding of principles like DRY shows the journey: first it's about copy-paste, then duplicate knowledge, then knowing when duplication is better than the wrong abstraction. The most effective teams aren't just faster—they understand impact and use their skills to find better impacts. |
| **MCP and the Future of AI Tools: High-Level, Specialized, Expert** | - [2025-05-01: MCP space heating up](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7323651574591873024)<br>- [2025-05-22: MCP tool design pitfalls](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7331132881068593154)<br>- [2025-05-25: MCP servers need fit-for-purpose APIs](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7332421344774471682) | As Model Context Protocol (MCP) matures, Stacey warns against lazy thinking—don't just expose your low-level API to LLMs and expect magic. What LLMs need differs from typical API docs. Tools need rich descriptions with when/why/examples, parameter descriptions explaining impact, not just what. It's like giving GenAI a screwdriver and hammer vs. giving it a general contractor and engineer who know how to use tools. Lines blur between multi-agent systems and single agents with powerful tools. |
| **The Map Is Not The Territory: What AI Can't Digitize** | - [2025-03-29: Map is not territory, feelings not digitizable](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7311710811691929601)<br>- [2025-03-30: Tacit knowledge and feelings](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7312040156763459584)<br>- [2025-05-07: Onsite customer and empathy](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7323862278129844224)<br>- [2025-08-22: LLMs only experience words](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7364623414080249856) | We can't digitize empathy, feeling, or tacit knowledge. LLMs experience only words—statistically muddied echoes of human expression. Humans experience through senses creating profound understanding. A text message can be misconstrued; imagine experiencing the world only via words. Professionals create affordances through empathy and rich interaction. Vibe-coding/designing is iterative interplay between LLM rendering and expert tacit knowledge (which feels like intuition). Your value isn't in typing code—it's in what you know from experience that can't be communicated in words. |
| **TDD at the Speed of Thought: Engineering Operations Not Code Generation** | - [2025-05-11: GenAI coding pattern - engineering operations](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7327308235550437376)<br>- [2025-07-10: Tests are spec, GenAI shouldn't write them](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7340035903396790272)<br>- [2025-05-19: TDD and correlation vs causation](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7330210381275029504) | Get past "Look, ma, it can code!" and start requesting engineering operations: reorganize for symmetry, extract tool registration, fix layer separation, mock dependencies. Act as code reviewer in your chat thread. Tell it functionality is OK, now improve the design. Watch how many files it touches—that tells you about cohesion. Tests expose layering problems. TDD isn't the determinant of success, but something deeper drives people with that capability to leverage TDD. If forcing/mandating TDD, it won't work. |
| **DevOps as Learning: Delegate the Drudgery, Keep the Discovery** | - [2025-11-06: Delegate to agents, keep coding](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392191067728658432)<br>- [2025-04-16: Mojentic library for Python LLM access](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7318110931417268224)<br>- [2023-10-21: Drudgery vs artisan learning](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7121484867770408960) | If you like coding, delegate other things to agents. Create tools if they don't exist. But consider: how much did we learn doing drudgery that made us better artisans? The doing takes only a moment, but who did it and what they learned matters if we intend to keep doing things. "Find a job, automate it away, then find another job." Working on MLCoder/stacey.py to automate the search-and-replace work. The future belongs to those who can out-learn the competition. |
| **Working in Public: Tools, Craft, and Canadian Tech** | - [2025-11-03: Weekend project renaming screenshots](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7390956641283911680)<br>- [2025-06-15: Prompt engineering benchmarking](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7339980390666805248)<br>- [2025-07-05: Building Context Mixer in the open](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7347264876697821185)<br>- [2025-09-16: Canadian tech and confidence](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7373690749424508928) | Stacey builds tools in the open: weekend projects, comparing agents (Copilot, Junie, Claude Code), developing Mojentic and Context Mixer frameworks, experimenting with local models. Each project explores developer ergonomics and tests assumptions. Reference: FF website error when Canada jobs program launched—"if Canadian tech companies want to do better, we need to pay attention to people who know how. We need to actually do better." Building Canadian and listening harder than McKinsey. |

## Key Themes and Insights

### **Context Engineering as the New Prompt Engineering**

The field is evolving from simple prompt design to sophisticated context management systems. Stacey's CRAFT framework (Chunk, Resist, Adapt, Fit, Transcend) provides a structured approach: breaking knowledge into composable atomic units, avoiding contradictions, adjusting abstraction levels for tasks, delivering only relevant information, and designing knowledge independent of storage platform. This parallels software compilation—moving from AOT (static prompts) to JIT (dynamic context assembly).

The insight: LLMs are trained on vast material including formal semantic models (DITA, RDF, OWL, Dublin Core). When plain English isn't providing semantic clarity, leveraging well-known ontological frameworks can dramatically improve interactions. Context engineering isn't just about feeding LLMs information—it's about structured knowledge management that transcends tools and platforms.

### **The Craft of Development in an AI-Augmented World**

A recurring tension: what is a developer's value when GenAI can type code? Stacey consistently argues that typing code was never the bottleneck—alignment, design decisions, tacit knowledge, and empathy are. "Vibe-coding" feels awful to experienced developers because they watch compounding loss of fidelity in real-time. Developers don't just type syntax; they make countless micro-decisions informed by experience that can't be fully articulated.

The "copilot pause"—when developers stop thinking to await suggestions—represents a harmful ergonomic pattern. Instead of measuring velocity, measure uncertainty pauses and what they reveal about language/framework knowledge, problem understanding, and domain expertise. The path forward isn't replacing developers but understanding what they actually do beyond typing.

### **Testing Non-Deterministic Systems Requires New Thinking**

GenAI systems produce variable results run-to-run. Traditional automated checking (asserting precise outputs) breaks down. Testing remains crucial—the creative human activity of experiencing system behavior to learn about the problem space. But checking requires new approaches: characterization with controlled seeds, parallel validation post-production, using different models for different purposes, and lab environments to benchmark exact prompt/model/version combinations.

Critical insight: Tests are executable specifications expressing intent. Never let GenAI modify them freely—it can't know your intent, only characterize existing code. Doing so rigidifies the system in ways you'll hate. The goal isn't any automated test; it's tests that clearly indicate what broke.

### **Ensemble Coding and Real-Time Intent Negotiation**

The bottleneck isn't coding speed—it's alignment. Time spent in unclear meetings, rework from lost translation, waiting for clarification. Stacey experiments with cross-functional teams (designer, PM, architect, developer) building together in real-time with LLMs as synthesis engines. Not mob programming where one types—real-time intent negotiation where designer corrects UX immediately, architect flags conflicts as they emerge, PM keeps scope in check.

The hypothesis: coordination failures drop when everyone sees their intent materialize into code immediately. This compresses weeks of back-and-forth into hours of productive synthesis. It's about dissolving translation layers between how people think and what gets built, not just making individual developers faster.

### **Essential vs. Accidental Complexity**

Essential complexity stems from real-world business domains. Accidental complexity comes from over-engineering, organizational misalignment, and "it works, don't touch it" mentality. At scale, complexity bleeds massive money through thin-sliced roles, overcomplicated infrastructure, and poor developer experience.

GenAI has two edges: trained on overcomplicated code, it happily replicates those patterns. But it can also slice through complexity like a machete when guided well. Simple requires more thought than complex. Use GenAI to delegate what keeps you from pursuing simplicity relentlessly. The biggest side effect GenAI brings: getting us talking and writing better about code as we struggle to guide agents.

### **The Unmappable Territory: Tacit Knowledge and Human Experience**

The map is not the territory. We can't digitize feelings, empathy, or tacit knowledge—the incommunicable knowing that comes through experience. You can't describe riding a bicycle to someone (human or AI) and have them immediately ride. They must learn through experience. LLMs only experience words, which is like experiencing the world via text messages—prone to misunderstanding.

Experienced developers' best decisions often come from "it felt right" after hundreds of iterations. The affordances built into work products come from empathy and compassion through rich interaction with customers. Those are what only you bring. This isn't romantic notion—it's practical reality. GenAI has no hands to touch the world, no senses except those we give it, no delight in right product experience at right time.

### **Knowledge Work Evolving: Delegation, Discovery, and Learning**

If you like coding, delegate other work to agents. But consider: how much did doing drudgery teach us to be better artisans? Balance tempered bionic enablement with organizational learning. The doing takes a moment, but who did it and what they learned matters for continuing to do things.

"Find a job, automate it away, find another job." Stacey builds tools (MLCoder/stacey.py, Context Mixer, Mojentic, zettelkasten assistants) while questioning what gets automated vs. what requires human judgment. The future belongs not to those who out-code the competition, but those who out-learn them. As AI changes knowledge work, professionals must articulate their unique value—not in outputs but in decision-making, pattern recognition, and continuous improvement.

### **Canadian Tech Ecosystem and Inclusion**

Throughout, there's attention to Canadian tech ecosystem health and authentic inclusion. When FF's website errors during Canada jobs program launch, it undermines confidence. Canadian businesses need to listen to actual practitioners harder than expensive consultants. Building Canadian means putting money where mouths are.

Inclusion threads through: recognizing cognitive biases in ourselves, creating psychological safety, understanding humans aren't rational, making space for diverse perspectives. The agile community's foundation was empathy, context, and human connection—increasingly important as transactional engagement and "superficial advice-giving of computational algorithms" threatens to replace coaching and mentorship.

### **Practical Tools and Developer Ergonomics**

Stacey consistently explores tools and frameworks: Mojentic for Python LLM access, Context Mixer for context engineering, MCP server implementations, local model exploration (Qwen, Gemma, prioritizing small capable models for power efficiency). Focus is always on developer ergonomics—how tools feel to use, whether they help or hinder flow.

Key insights on tools: MCP servers need rich, fit-for-purpose APIs with when/why/examples, not just low-level function exposure. Lines blur between multi-agent systems and single agents with powerful specialized tools. Don't just give LLM a screwdriver and hammer; give it a general contractor who knows when to use them.
