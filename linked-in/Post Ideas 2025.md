# LinkedIn Post Ideas - 2025

## Proposed Blog Posts

| Proposed blog post (working title) | Source material & URLs | Notes |
|-----------------------------------|------------------------|-------|
| **The Taxonomy of Slop: Understanding GenAI Reliability** | - [2025-12-09: GenAI reliability and slop types](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7404135747139829761)<br>- [2025-12-08: Senior engineers leveraging GenAI best](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7403773197634138112)<br>- [2025-05-31: Claude claiming 67% pass rate acceptable](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7334382412480630784) | GenAI doesn't need compiler-level reliability because humans are the "OG non-deterministic." There's a hierarchy of slop types by decreasing cost: solving the wrong problem, solving the problem wrong, misunderstanding technology, bad planning, bad code. The world runs on bad code that works. Senior devs leverage GenAI best not because of how they apply AI, but how they think about engineering. A humorous example: Claude claiming 67% test pass rate is acceptable. |
| **The CRAFT Framework: Context Engineering for the LLM Era** | - [2025-08-15: CRAFT - Transcend](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7362086675914579970)<br>- [2025-08-13: CRAFT - Fit](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7361353128119529473)<br>- [2025-07-29: CRAFT - Adapt](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7355928475037253633)<br>- [2025-07-19: CRAFT - Resist](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7352293432544927745)<br>- [2025-07-15: CRAFT - Chunk](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7350851966333329410)<br>- [2025-07-03: Context Engineering patterns](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7346489429127032832) | A cohesive series introducing CRAFT (Chunk, Resist, Adapt, Fit, Transcend) as a framework for context engineering with LLMs. Chunk: build small, composable knowledge units. Resist: keep knowledge free of contradictions. Adapt: adjust detail level for the task. Fit: deliver only what's relevant. Transcend: design knowledge independent of storage platform. Context engineering is the new prompt engineering—moving from AOT (static prompts) to JIT (dynamic context assembly). |
| **Conceptual Models as Design Language: JSON, Images, and Cross-Discipline Creativity** | - [2025-12-04: JSON conceptual models for images](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7402339597147537408)<br>- [2025-01-25: LLMs trained on semantic models](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7288917830987599872) | People discovered you can build a conceptual model behind an image as JSON, and models like Gemini's "Nano Banana" will render it—or extract JSON from images. This formalizes design language grammars with JSON Schema. Visual designers are increasingly building design languages, not just pretty pictures. LLMs are trained on formal semantic models (DITA, RDF, OWL, Dublin Core)—leverage well-known ontological frameworks when plain English isn't providing semantic clarity. |
| **The Shifting Line of Determinism: GenAI Is Not Your Compiler** | - [2025-12-01: GenAI vs compiler/determinism](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7401238252621557761)<br>- [2025-11-11: Mojentic Elixir/Rust porting - data modeling philosophy](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7393855740081459200)<br>- [2025-07-20: Non-determinism as asset for ideation](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7352796623506141185)<br>- [2025-02-22: Quality in a GenAI world](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7299063072713822208) | GenAI isn't literally a compiler, but there's always been a march toward non-determinism even in CPUs and compilers—pipelining, optimization. What IS deterministic is always shifting because life isn't deterministic. Non-determinism is a tremendous asset for ideation—use multiple agents, examine different approaches, pre-iterate before delivery. Extends to data modeling philosophy: Python/Pydantic (runtime validation), Elixir (pattern matching IS validation), Rust (compile-time guarantees). |
| **Agentic Tools and Nested Context: The Monorepo-Submodule Approach** | - [2025-12-01: Git submodules and mojentic multilang](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7401220228992565248)<br>- [2025-11-17: VS Code custom agents experience](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7396174502898085890)<br>- [2025-05-22: MCP implementation and developer ergonomics](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7331132881068593154)<br>- [2025-05-01: MCP space heating up](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7323651574591873024) | Git submodules enable monorepo-like structure while keeping libraries independent. Mojentic spans Python, Rust, Elixir, Typescript with idiomatic designs per language. Agentic tools that respect nested AGENTS.md or CLAUDE.md handle this best; Windsurf struggles with singular project analysis. MCP is maturing but needs fit-for-purpose APIs with rich descriptions, when/why/examples, not just low-level function exposure. Lines blur between multi-agent systems and single agents with powerful tools. |
| **Beyond Vibe-Coding: What Developers Actually Do** | - [2025-08-19: Software development profound change](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7363543690583105536)<br>- [2025-05-04: Vibe-coding relegating corners](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7324809322721435649)<br>- [2025-03-22: Vibe-coding mental model drift](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7309146789880713216)<br>- [2025-05-16: Docs are docs from far away](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7329091538653753344) | These shares challenge "vibe-coding" and question what happens when developers' understanding drifts from reality. From far enough away, all a developer does is type code. The time is past due to dig deeper towards what developers actually do—design decisions, tacit knowledge, mental models. "Vibe-coding" feels awful to experienced developers because we watch the compounding loss of fidelity in real-time. Your value isn't in typing code—it's in what you know from experience. |
| **The Copilot Pause: When AI Interrupts Developer Flow** | - [2025-02-02: Co-pilot pause damaging ergonomic impact](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7291811583922503680)<br>- [2025-11-08: GenAI plan execution and learning](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392902690441285632)<br>- [2025-04-15: See every test fail](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7318047044026195968) | The "co-pilot pause" represents moments when developers stop thinking to await external suggestions, interrupting flow and derailing original thought. Want a metric? How often we pause, and what uncertainty caused it—language, library, solution, domain. When I know a language/framework, coding assistants create back-pressure against productivity. Plans should be updated as we learn during execution—our tacit knowledge comes into play. |
| **Essential vs. Accidental Complexity: Where Your Money Goes** | - [2025-11-07: Essential vs accidental complication](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392521881846906880)<br>- [2025-11-07: Software team roles changing](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392358378699792384)<br>- [2025-10-10: Pattern replication and CRUD](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7382356132478095360)<br>- [2025-11-07: Developers and ROI data](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392552123386789888) | Essential complexity comes from the real-world business domain; accidental complexity comes from over-engineering and organizational dysfunction. At scale, complexity bleeds massive money. GenAI has two edges: it replicates overcomplicated patterns from training data, but can slice through complexity like a machete when guided well. Simple is hard and requires thought. Current agents still fight on simplicity—they haven't seen a lot of examples. It's what they need us for. |
| **The Ensemble Coding Hypothesis: Real-Time Intent Negotiation** | - [2025-10-12: Alignment is the real bottleneck](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7383116191772409857)<br>- [2025-10-13: Visualizing higher-order concerns from code](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7383490712064925696)<br>- [2025-10-12: Prototyping Actor/Goal/Task system](https://www.linkedin.com/feed/update/urn%3Ali%3AugcPost%3A7383285787649388544)<br>- [2025-10-22: ScreenPlay Pattern and Story Mapping](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7386909269096407040) | The bottleneck isn't coding speed—it's alignment. Time spent in unclear meetings, rework from lost translation, waiting for clarification. Cross-functional ensemble coding sessions (designer, PM, architect, developer) building together in real-time with LLM as synthesis engine. Not mob programming—real-time intent negotiation where everyone corrects immediately. What if everyone could see higher-order concerns (architecture, design, interaction) from the reality of the code? |
| **Testing the Non-Deterministic: Quality in the GenAI Era** | - [2025-02-22: Quality in a GenAI world](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7299063072713822208)<br>- [2025-02-20: Tests never contain conditionals](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7298316100268666881)<br>- [2025-07-10: Tests are spec, GenAI shouldn't write them](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7349035622684086272)<br>- [2025-07-15: METR study context](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7350872433278480386) | Building software with LLMs produces non-deterministic results, fundamentally changing testing. Tests are executable specifications expressing intent—never let GenAI modify them freely. Test code should never contain conditionals—a conditional signals the test checks too many things. GenAI can only characterize existing code; having it write tests rigidifies the system in ways you'll hate. Exploit non-determinism rather than trying to crush it. |
| **The Map Is Not The Territory: What AI Can't Digitize** | - [2025-03-29: Map is not territory, feelings not digitizable](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7311710811691929601)<br>- [2025-03-30: Tacit knowledge and feelings](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7312040156763459584)<br>- [2025-08-22: LLMs only experience words](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7364623414080249856)<br>- [2025-08-22: LLMs and affordances](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7364635455083945984) | We can't digitize empathy, feeling, or tacit knowledge. LLMs experience only words—statistically muddied echoes of human expression. Imagine experiencing the world only via text messages. Tacit knowledge is incommunicable by words—you can't describe riding a bicycle and have someone immediately ride. Your best decisions often come from "it felt right" after hundreds of iterations. The affordances in your work products come from empathy through rich interaction with customers. |
| **TDD at the Speed of Thought: Engineering Operations Not Code Generation** | - [2025-05-11: GenAI coding pattern - engineering operations](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7327308235550437376)<br>- [2025-05-19: TDD and correlation vs causation](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7330210381275029504)<br>- [2025-02-17: Engineering transformations](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7297308378303746050) | Get past "Look, ma, it can code!" Request engineering operations: reorganize for symmetry, extract tool registration, fix layer separation, mock dependencies. Act as code reviewer in your chat thread. Tell it functionality is OK, now improve the design. Watch how many files it touches—that tells you about cohesion. If TDD isn't the determinant of success, something else drives people with that capability to leverage it. If forcing TDD, it won't work. |
| **DevOps as Learning: Delegate the Drudgery, Keep the Discovery** | - [2025-11-06: Delegate to agents, keep coding](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392191067728658432)<br>- [2025-05-02: Out-learn the competition](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7324036338398240769)<br>- [2025-06-20: GenAI and brain rot studies](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7341806066537562112) | If you like coding, delegate other things to agents. Create tools if they don't exist. But consider: how much did we learn doing drudgery that made us better artisans? Studies claiming GenAI rots your brain—remember behaviour is one thing, cognitive capability is different. We evolved to preserve energy until it matters. The future belongs to those who out-learn the competition. Learning plus output: balancing doing the work and doing it better in the future. |
| **Lines of Code: The Productivity Zombie That Won't Die** | - [2025-11-20: Lines of Code productivity measurement](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7397249115824345088)<br>- [2025-11-07: Developers and ROI data](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7392552123386789888)<br>- [2025-02-14: Objectives vs tasks](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7296151867712045058) | "If your goal is to stay busy rather than have impact, measure productivity by Lines of Code." Why is this resurging? Effective teams know how everything they do impacts the business—they're not short-order cooks. Elevate from thinking about tasks/capabilities to outcomes/objectives. A capability is not an objective; it's means to an objective. The shear line between daily tasks and why we're doing them reveals waste in the system. |
| **Desktop UI Is Not Web UI: The Nerfed Experience** | - [2025-11-25: LLMs and web UI vs desktop UI](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7399065868984283136)<br>- [2025-05-01: Future of UI - tactile, touchscreen, or voice](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7323653741218258945) | "LLMs getting better at UI" tends to mean wrangling web UI. Web UI is a necessary evil for demand, but it's not and can never be excellent UI. Desktop UI (Qt, etc.) is tremendously rich; browsers significantly nerf capabilities. Gemini Pro 3 produces horribly unstable experiences with Qt: inconsistent visual design adherence, horrible concurrency and event handling. What's the future—more sophisticated tactile UI, elaborate touchscreen, or Star Trek voice commands? |
| **Knowledge Management as Code: From Zettelkasten to Context Engineering** | - [2025-01-04: Zettelkasten and hierarchical knowledge management](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7281315524020432899)<br>- [2025-01-04: Knowledge graphs and multilayer hallucination](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7281319125887381504)<br>- [2025-02-17: Text transcription benchmark](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7297245095680987136) | The intersection of personal knowledge management (Zettelkasten/Atomic Notes), structured LLM responses, and hierarchical knowledge systems. Knowledge management resembles compilation—moving from AOT (static prompts) to JIT (dynamic context assembly). Multilayer hallucination across extracted knowledge graphs is even more challenging than single-layer hallucination. Google's Gemma2 9B is the rock-star for accurate text transcription on prosumer hardware. |
| **Gherkin, BDD, and the GenAI Opportunity** | - [2025-09-26: Gherkin and BDD perspective](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7377308693459050496)<br>- [2025-09-03: Markdown specs as make-work](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7368960648082251778) | Don't bother with Gherkin if nobody consumes the content. Write "tests" from the BDD perspective. GenAI excels at word and idea refactoring—exposing assumptions, finding gaps through elaborating and summarizing. Round-trip validation: English→French→English to rate the translator. The only adequately precise specification for a system is its source code—why are we tinkering with markdown specs just to force ourselves to use GenAI? |
| **Interactionalism and the Future of Learning** | - [2025-04-03: Symmathesy and Interactionalism](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7313371709472944128)<br>- [2025-09-24: Technology and authentic human use](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7376764106571218944) | Nora Bateson's Symmathesy: a living system that learns through contextual, mutual interaction. Interactionalism: moving away from one-directional knowledge transfer toward dynamic, back-and-forth learning where humans and AI evolve together. The technology is the technology, but what makes the world turn is how we use it together, how it could help us be who we are more authentically. We learn best together as humans, now with a new teammate in AI. |
| **Simple Is Hard: Why Developers Need to Own Complexity** | - [2025-05-26: SRP discourse between Martin and Ousterhout](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7332723052461395969)<br>- [2025-02-18: DRY evolution](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7297610953204912128)<br>- [2025-05-11: Break down work into small batches](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7327355567239303168) | "It's supposed to help you think, not relieve you of the burden of thinking." Robert Martin vs John Ousterhout on small methods—neither wrong nor right, the discourse clarifies the questions. DRY evolution: first about copy-paste, then duplicate knowledge, then knowing when duplication is better than the wrong abstraction. Breaking down work is substantially harder than getting pieces done. If you think getting pieces done is hard, do poorly at breaking problems down and it will be. |
| **Working in Public: Tools, Craft, and Canadian Tech** | - [2025-11-03: Weekend project renaming screenshots](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7390956641283911680)<br>- [2025-06-15: Prompt engineering benchmarking](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7340045903396790272)<br>- [2025-07-05: Building Context Mixer in the open](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7347264876697821185)<br>- [2025-09-16: Canadian tech and confidence](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7373690749424508928) | Building tools in the open: weekend projects, comparing agents, developing Mojentic and Context Mixer, experimenting with local models (Qwen, Gemma). Focus is developer ergonomics—how tools feel to use. Canadian tech: if we want to do better, we need to listen to people who know how—harder than McKinsey. Web development is 10x worse than 10 years ago; MCP is coming of age with resources and prompts. |
| **MCP and the Future of AI Tools: High-Level, Specialized, Expert** | - [2025-05-01: MCP space heating up](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7323651574591873024)<br>- [2025-05-22: MCP tool design pitfalls](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7331132881068593154)<br>- [2025-05-25: MCP servers need fit-for-purpose APIs](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7332421344774471682)<br>- [2025-03-22: Don't just hand low-level tools](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7309184816812347393) | Don't just expose your low-level API to LLMs and expect magic. Tools need rich descriptions with when/why/examples, parameter descriptions explaining impact. It's like giving GenAI a screwdriver and hammer vs. giving it a general contractor and engineer who know how to use tools. Lines blur between multi-agent systems and single agents with powerful tools. Tools remain a great mechanism for the boundary between probabilistic and deterministic solvers. |
| **Generative Music to Generative Code: 50 Years of Not Replacing Creators** | - [2025-01-24: Generative music hasn't obsoleted bands](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7288516590013214720)<br>- [2025-01-14: ChatGPT making obvious what not to say](https://www.linkedin.com/feed/update/urn%3Ali%3Ashare%3A7284742408867569664) | In 50 years, generative music from Wendy Carlos to Deadmau5 hasn't obsoleted musicians forming bands. GenAI code assistants won't displace developers coming together to synthesize new technology. Synths went from generating tones to arpeggios to backing tracks—software has explored meta-programming, modeling, now generating small systems. What business are you in? Commodities, creators, or the flow between? ChatGPT makes obvious what not to say, so you can choose ideas with impact. |

## Key Themes and Insights

### **Context Engineering as the New Prompt Engineering**

The field is evolving from simple prompt design to sophisticated context management systems. Stacey's CRAFT framework (Chunk, Resist, Adapt, Fit, Transcend) provides a structured approach: breaking knowledge into composable atomic units, avoiding contradictions, adjusting abstraction levels for tasks, delivering only relevant information, and designing knowledge independent of storage platform. This parallels software compilation—moving from AOT (ahead-of-time prompts) to JIT (just-in-time context assembly).

The insight: LLMs are trained on vast material including formal semantic models (DITA, RDF, OWL, Dublin Core). When plain English isn't providing semantic clarity, leveraging well-known ontological frameworks can dramatically improve interactions. Context engineering isn't just about feeding LLMs information—it's about structured knowledge management that transcends tools and platforms. The Context Mixer product represents a reference implementation for these ideas.

### **The Craft of Development in an AI-Augmented World**

A recurring tension: what is a developer's value when GenAI can type code? Stacey consistently argues that typing code was never the bottleneck—alignment, design decisions, tacit knowledge, and empathy are. "Vibe-coding" feels awful to experienced developers because they watch compounding loss of fidelity in real-time. Developers don't just type syntax; they make countless micro-decisions informed by experience that can't be fully articulated.

The "copilot pause"—when developers stop thinking to await suggestions—represents a harmful ergonomic pattern. Instead of measuring velocity, measure uncertainty pauses and what they reveal about language/framework knowledge, problem understanding, and domain expertise. The path forward isn't replacing developers but understanding what they actually do beyond typing. From far enough away, docs are docs, features are features, coding is typing—but the thing YOU do, those intangible tacit skills, bring success.

### **The Taxonomy of Slop and GenAI Reliability**

GenAI doesn't need to be as reliable as a compiler because humans are the "OG non-deterministic." There's a hierarchy of slop types ordered by decreasing cost and increasing blast radius: solving the wrong problem, solving the problem wrong, misunderstanding the technology, bad planning, bad code. The world runs on bad code that happens to work—solving the right problem well enough. Solving the wrong problem with beautiful code is a special kind of purgatory.

Senior developers leverage GenAI best not because of how they apply AI, but because of how they think about software engineering in general. If you want improvement in engineering from GenAI, look to improve engineering practices first. "Programming by remote control" is a costly, slop-building thing—GenAI wasn't the first approach to develop slop.

### **Testing Non-Deterministic Systems Requires New Thinking**

GenAI systems produce variable results run-to-run. Traditional automated checking (asserting precise outputs) breaks down. Testing remains crucial—the creative human activity of experiencing system behavior to learn about the problem space. But checking requires new approaches: characterization with controlled seeds, parallel validation post-production, using different models for different purposes, and lab environments to benchmark exact prompt/model/version combinations.

Critical insight: Tests are executable specifications expressing intent. Never let GenAI modify them freely—it can't know your intent, only characterize existing code. Doing so rigidifies the system in ways you'll hate. Test code should never contain conditionals—a conditional signals the test checks too many things. The goal isn't any automated test; it's tests that clearly indicate what broke.

### **Ensemble Coding and Real-Time Intent Negotiation**

The bottleneck isn't coding speed—it's alignment. Time spent in unclear meetings, rework from lost translation, waiting for clarification. Stacey experiments with cross-functional teams (designer, PM, architect, developer) building together in real-time with LLMs as synthesis engines. Not mob programming where one types—real-time intent negotiation where designer corrects UX immediately, architect flags conflicts as they emerge, PM keeps scope in check.

The hypothesis: coordination failures drop when everyone sees their intent materialize into code immediately. This compresses weeks of back-and-forth into hours of productive synthesis. What if everyone could see higher-order concerns (architecture, design, interaction) directly from the code? The real power of AI in development might be getting cross-functional teams aligned, not just making individual developers more productive in isolation.

### **Essential vs. Accidental Complexity**

Essential complexity stems from real-world business domains. Accidental complexity comes from over-engineering, organizational misalignment, and "it works, don't touch it" mentality. At scale, complexity bleeds massive money through thin-sliced roles, overcomplicated infrastructure, and poor developer experience.

GenAI has two edges: trained on overcomplicated code, it happily replicates those patterns. But it can also slice through complexity like a machete when guided well. Simple requires more thought than complex. Use GenAI to delegate what keeps you from pursuing simplicity relentlessly. Current agents still fight on simplicity—they haven't seen a lot of examples. That's what they need us for. The biggest side effect GenAI brings: getting us talking and writing better about code as we struggle to guide these agents.

### **The Unmappable Territory: Tacit Knowledge and Human Experience**

The map is not the territory. We can't digitize feelings, empathy, or tacit knowledge—the incommunicable knowing that comes through experience. You can't describe riding a bicycle to someone (human or AI) and have them immediately ride. They must learn through experience. LLMs only experience words, which is like experiencing the world via text messages—prone to misunderstanding.

Experienced developers' best decisions often come from "it felt right" after hundreds of iterations. The affordances built into work products come from empathy and compassion through rich interaction with customers. Those are what only you bring. This isn't romantic notion—it's practical reality. GenAI has no hands to touch the world, no senses except those we give it, no delight in right product experience at right time. Vibe-coding/designing is iterative interplay between LLM rendering and expert tacit knowledge (which feels like intuition).

### **Agentic Tools and Nested Context Management**

Git submodules enable monorepo-like structure while keeping individual libraries and their build automation independent. This provides higher-order policy, use-case, and intent guidelines common between all libraries while accommodating variability and commonality in different directions. Agentic tools that respect nested AGENTS.md or Claude Code's nestable CLAUDE.md handle this best; tools wanting singular technology analysis struggle.

This enables powerful workflows: daily automated dependency security sweeps, adding use-cases to executive documentation and letting specialized sub-agents ripple implications through each submodule, bringing technical capabilities and documentation standards in sync while avoiding shoe-horning awkward technology or policy mixes. Agent formations gorge on tokens—the scale of what's "big" is completely different now.

### **MCP and the Future of AI Tools**

As Model Context Protocol matures, Stacey warns against lazy thinking—don't just expose your low-level API to LLMs and expect magic. What LLMs need differs from typical API docs. Tools need rich descriptions with when/why/examples, parameter descriptions explaining impact, not just what. It's like giving GenAI a screwdriver and hammer vs. giving it a general contractor and engineer who know how to use tools.

Lines blur between multi-agent systems with an executive and team of specialists, and a single agent with a bucket of professional high-level tools. Tools remain a great mechanism for the boundary between probabilistic solvers (LLMs) and deterministic solvers. The MCP ecosystem is currently a bit of a cesspool, but useful expert-oriented tools are emerging.

### **Knowledge Work Evolving: Delegation, Discovery, and Learning**

If you like coding, delegate other work to agents. But consider: how much did doing drudgery teach us to be better artisans? Balance tempered bionic enablement with organizational learning. The doing takes only a moment, but who did it and what they learned matters for continuing to do things.

Studies claiming GenAI rots your brain—remember behavior is one thing, cognitive capability is different. We evolved to preserve energy consumption until it matters. The future belongs not to those who out-code the competition, but those who out-learn them. Symmathesy and Interactionalism point toward dynamic, back-and-forth learning environments where humans and AI evolve together.

### **Canadian Tech Ecosystem and Professional Practice**

Throughout, there's attention to Canadian tech ecosystem health. When government sites error during program launches, it undermines confidence. Canadian businesses need to listen to actual practitioners harder than expensive consultants. Building Canadian means putting money where mouths are.

Web development is 10 times worse than it was 10 years ago—the cognitive load is too damn high. MCP is coming of age. Knowledge management, presentation, and communication are paramount. Organizations like Stripe and Twilio succeeded through documentation and socialization that said "you can do this"—far more impactful than "here's our API documentation."

### **Practical Tools and Developer Ergonomics**

Stacey consistently explores tools and frameworks: Mojentic for Python/Rust/Elixir/Typescript LLM access, Context Mixer for context engineering, MCP server implementations, local model exploration (Qwen, Gemma, prioritizing small capable models for power efficiency). Focus is always on developer ergonomics—how tools feel to use, whether they help or hinder flow.

Key insight: favor declarative code over imperative code—easier to test and less error prone. Use LLMs to perform engineering transformations (reorganize for symmetry, extract registration patterns, fix layer separation). Act as code reviewer in your agentic chat thread. Watch how many files changes touch—that reveals cohesion. Build baseline instructions modularly, swap parts in and out based on what the agent follows.

### **The Four Rules of Simple Design Keep Giving**

Recurring throughout is the influence of Kent Beck's Four Rules of Simple Design: passes all tests, reveals intent, no knowledge duplication, minimal entities. These apply remarkably well to context engineering, MCP tool design, testing philosophy, and code review guidance. When designing APIs or tools for LLM consumption, the expressive richness demanded by "reveals intent" matters even more—you can't assume human experience, only rote regurgitation.

DRY evolves: first about copy-paste, then duplicate knowledge, then knowing when duplication is better than the wrong abstraction. It costs less over time to do things we tell less experienced devs never to do. Breaking down work is substantially harder than getting pieces done—if you do poorly at breaking problems down, getting them done certainly will be hard.
